{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat_vs_Dog_small.ipynb  \u001b[34mdata\u001b[m\u001b[m/                   kerashelloworld.ipynb\r\n",
      "Iris_sanguinea.JPG      keras_MNIST.ipynb       \u001b[34mpreview\u001b[m\u001b[m/\r\n",
      "WordEmbed.ipynb         keras_MNIST.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a small convnet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 148, 148)  896         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 148, 148)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 74, 74)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 72, 72)    9248        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 72, 72)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 36, 36)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 34, 34)    18496       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 34, 34)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 64, 17, 17)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 64)            1183808     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64)            0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             65          dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 1)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s - loss: 0.0348 - acc: 1.0000 - val_loss: 1.9637 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 1s - loss: 0.0289 - acc: 1.0000 - val_loss: 2.3141 - val_acc: 0.4500\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 1s - loss: 0.0473 - acc: 1.0000 - val_loss: 2.9762 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 1s - loss: 0.0470 - acc: 0.9500 - val_loss: 1.9951 - val_acc: 0.6000\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 1s - loss: 0.0109 - acc: 1.0000 - val_loss: 2.1362 - val_acc: 0.6000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 1s - loss: 0.0053 - acc: 1.0000 - val_loss: 2.2314 - val_acc: 0.6000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 1s - loss: 0.0360 - acc: 1.0000 - val_loss: 2.2316 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 1s - loss: 0.0929 - acc: 0.9500 - val_loss: 1.9233 - val_acc: 0.6500\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 1s - loss: 0.0383 - acc: 1.0000 - val_loss: 2.3830 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 1s - loss: 0.0167 - acc: 1.0000 - val_loss: 2.6700 - val_acc: 0.4500\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=20,     #should be 2000, but i just use a sample data set\n",
    "        nb_epoch=10,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=20)         #should be 800\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the bottleneck features of a pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# path to the model weights file.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000   #should be 2000\n",
    "nb_validation_samples = 800    #should be 800\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # load the weights of the VGG16 networks\n",
    "    # (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "    # note: when there is a complete match between your model definition\n",
    "    # and your weight savefile, you can simply call model.load_weights(filename)\n",
    "    assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "    f = h5py.File(weights_path)\n",
    "    layers = f.attrs.values()\n",
    "    for k in range(len(layers)):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "\n",
    "    \n",
    "    ## generator data and save features calculated by pre-trained model\n",
    "    generator = datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)    #change to 'wb'\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can try this actually: https://keras.io/applications/#vgg16\n",
    "* Load a full vgg16, load weights, pop top layers and freeze convnet layers\n",
    "* calculate feature is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "model =  VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(3, img_width, img_height))  \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "generator = datagen.flow_from_directory(\n",
    "            'data/valid',\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=20,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "\n",
    "features_validation = model.predict_generator(generator, 20)\n",
    "np.save(open('vgg16feature_validation.npy', 'wb'), features_validation)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "    train_labels = np.array([0] * int(nb_train_samples / 2) + [1] * int(nb_train_samples / 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "    validation_labels = np.array([0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=32,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 0s - loss: 0.6933 - acc: 0.4000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s - loss: 0.6913 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s - loss: 0.6887 - acc: 0.8000 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s - loss: 0.6904 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s - loss: 0.6952 - acc: 0.5000 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s - loss: 0.6859 - acc: 0.7000 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s - loss: 0.6859 - acc: 0.7000 - val_loss: 0.6942 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s - loss: 0.6892 - acc: 0.6500 - val_loss: 0.6946 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s - loss: 0.6920 - acc: 0.5000 - val_loss: 0.6947 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s - loss: 0.6918 - acc: 0.6000 - val_loss: 0.6948 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s - loss: 0.6956 - acc: 0.4500 - val_loss: 0.6948 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s - loss: 0.6881 - acc: 0.5500 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s - loss: 0.6902 - acc: 0.7500 - val_loss: 0.6950 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s - loss: 0.6837 - acc: 0.7500 - val_loss: 0.6951 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s - loss: 0.6955 - acc: 0.3500 - val_loss: 0.6951 - val_acc: 0.5500\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s - loss: 0.6906 - acc: 0.5500 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s - loss: 0.6865 - acc: 0.7000 - val_loss: 0.6951 - val_acc: 0.4500\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s - loss: 0.6947 - acc: 0.5000 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s - loss: 0.6887 - acc: 0.7000 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s - loss: 0.6895 - acc: 0.5500 - val_loss: 0.6956 - val_acc: 0.3000\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s - loss: 0.6817 - acc: 0.7000 - val_loss: 0.6956 - val_acc: 0.4000\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s - loss: 0.6915 - acc: 0.5500 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s - loss: 0.6851 - acc: 0.7500 - val_loss: 0.6958 - val_acc: 0.4000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s - loss: 0.6809 - acc: 0.5500 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s - loss: 0.6906 - acc: 0.4000 - val_loss: 0.6960 - val_acc: 0.3500\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s - loss: 0.6865 - acc: 0.6500 - val_loss: 0.6960 - val_acc: 0.3000\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s - loss: 0.6855 - acc: 0.6000 - val_loss: 0.6962 - val_acc: 0.3000\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s - loss: 0.6807 - acc: 0.7000 - val_loss: 0.6964 - val_acc: 0.3000\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s - loss: 0.6822 - acc: 0.7500 - val_loss: 0.6963 - val_acc: 0.3000\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s - loss: 0.6799 - acc: 0.7500 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s - loss: 0.6892 - acc: 0.6000 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s - loss: 0.6867 - acc: 0.6000 - val_loss: 0.6967 - val_acc: 0.3000\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s - loss: 0.6757 - acc: 0.8000 - val_loss: 0.6968 - val_acc: 0.3500\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s - loss: 0.6797 - acc: 0.7000 - val_loss: 0.6968 - val_acc: 0.3500\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s - loss: 0.6844 - acc: 0.5500 - val_loss: 0.6971 - val_acc: 0.3000\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s - loss: 0.6721 - acc: 0.7500 - val_loss: 0.6972 - val_acc: 0.3500\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s - loss: 0.6892 - acc: 0.6000 - val_loss: 0.6973 - val_acc: 0.3000\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s - loss: 0.6823 - acc: 0.6000 - val_loss: 0.6974 - val_acc: 0.3000\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s - loss: 0.6816 - acc: 0.7000 - val_loss: 0.6975 - val_acc: 0.3000\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s - loss: 0.6822 - acc: 0.6000 - val_loss: 0.6977 - val_acc: 0.3000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s - loss: 0.6855 - acc: 0.4500 - val_loss: 0.6978 - val_acc: 0.3000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s - loss: 0.6867 - acc: 0.5500 - val_loss: 0.6979 - val_acc: 0.3000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s - loss: 0.6826 - acc: 0.6000 - val_loss: 0.6980 - val_acc: 0.3000\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s - loss: 0.6877 - acc: 0.6500 - val_loss: 0.6982 - val_acc: 0.3500\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s - loss: 0.6783 - acc: 0.8000 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s - loss: 0.6788 - acc: 0.6500 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s - loss: 0.6819 - acc: 0.7000 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s - loss: 0.6735 - acc: 0.7500 - val_loss: 0.6988 - val_acc: 0.4000\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s - loss: 0.6757 - acc: 0.6500 - val_loss: 0.6989 - val_acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the top layers of a a pre-trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve our previous result, we can try to \"fine-tune\" the last convolutional block of the VGG16 model alongside the top-level classifier. Fine-tuning consist in starting from a trained network, then re-training it on a new dataset using very small weight updates. In our case, this can be done in 3 steps:\n",
    "\n",
    "* instantiate the convolutional base of VGG16 and load its weights\n",
    "* add our previously defined fully-connected model on top, and load its weights\n",
    "* freeze the layers of the VGG16 model up to the last convolutional block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "* in order to perform fine-tuning, all layers should start with properly trained weights: for instance you should not slap a randomly initialized fully-connected network on top of a pre-trained convolutional base. This is because the large gradient updates triggered by the randomly initialized weights would wreck the learned weights in the convolutional base. In our case this is why we first train the top-level classifier, and only then start fine-tuning convolutional weights alongside it.\n",
    "* we choose to only fine-tune the last convolutional block rather than the entire network in order to prevent overfitting, since the entire network would have a very large entropic capacity and thus a strong tendency to overfit. The features learned by low-level convolutional blocks are more general, less abstract than those found higher-up, so it is sensible to keep the first few blocks fixed (more general features) and only fine-tune the last one (more specialized features).\n",
    "* fine-tuning should be done with a very slow learning rate, and typically with the SGD optimizer rather than an adaptative learning rate optimizer such as RMSProp. This is to make sure that the magnitude of the updates stays very small, so as not to wreck the previously learned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
